{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tema 1 - Skel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UTYLEhD_BM06",
        "67UlrcAdqj3N",
        "te02bqsfMhls",
        "HhdeP2WuL1AE",
        "FOsgPbZl1_W6",
        "iXlSfuvvzzFT",
        "RxCYjmzTM82o",
        "42KuhlsjfZLR",
        "NiqnAbGQpEVi"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-pub-ro/ML/blob/master/homework/hw1/Tema_1_Skel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDsijK1tlD3l",
        "colab_type": "text"
      },
      "source": [
        "# Tema 1 - A taste for music\n",
        "## Găsirea genului pentru piese\n",
        "\n",
        "### Autori: \n",
        "* George Muraru\n",
        "* Alexandru Sorici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTYLEhD_BM06",
        "colab_type": "text"
      },
      "source": [
        "## 1. Scopul temei\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkKFf7mEg8oZ",
        "colab_type": "text"
      },
      "source": [
        "Tema are ca scop folosirea metodelor de clasificare studiate în cadrul cursului/laboratorului pentru a **determina genul muzical** al unor sample-uri audio dintr-un set de date.\n",
        "\n",
        "Se doreste intelegerea procedurii tipice de **prelucrare a unui set de date**, de **explorare a atributelor**, precum si efectuarea unei **analize comparative** a mai multor algoritmi de clasificare, evidentiand diferentele intre ei prin metrici precum *acuratete, precizie, regasire (recall)*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67UlrcAdqj3N",
        "colab_type": "text"
      },
      "source": [
        "## 2. Set de date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEvxaYvXhAn7",
        "colab_type": "text"
      },
      "source": [
        "Primul pas în orice problema de data science este încărcarea și \"înțelegerea\" datelor.\n",
        "\n",
        "Setul de date utilizat poartă denumirea de Free Music Archive [[1]](#fma). \n",
        "\n",
        "Dataset-ul utilizat este \"usor\" modificat - va conține doar 4 genuri muzicale: *Rock*, *Hip-Hop*, *Folk* și *Electronic*.\n",
        "\n",
        "Setul de date este deja echilibrat -- sunt câte 500 de piese din fiecare gen în setul de train și câte 50 în cel de testare.\n",
        "\n",
        "Dacă setați parametrul [DOWNLOAD_SAMPLE_DATASET](#scrollTo=te02bqsfMhls) se va descărca și un audio sample pentru fiecare track_id atunci când se rulează celula specifică pentru secțiunea [Descărcare](#scrollTo=RxCYjmzTM82o).\n",
        "\n",
        "Puteți asculta sample-ul din piesă [aici](#scrollTo=te02bqsfMhls).\n",
        "\n",
        "Se va folosi drept **clasă** (eticheta care trebuie prezisa) *genul muzical cel mai general* (numele coloanei în engleza este *top_genre*) pentru fiecare piesă.\n",
        "\n",
        "\n",
        "Setul de date conține pentru fiecare sample mai multe atribute (eng. features), de tip numeric, care pot fi folosite pentru clasificare. Acestea pot fi găsite în fișierele *features.csv* sau *echonest.csv*.\n",
        "\n",
        "\n",
        "Pentru mai multe informații privind setul de date, se poate consulta [acest repository](https://github.com/mdeff/fma).\n",
        "\n",
        "Dataset-ul utilizat este o copie ușor modificată a celor [3 dataset-uri](https://github.com/mdeff/fma#Data): *fma_small.zip*, *fma_medium.zip*, *fma_large.zip*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKLOmyV707aI",
        "colab_type": "text"
      },
      "source": [
        "## 3. Workspace Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te02bqsfMhls",
        "colab_type": "text"
      },
      "source": [
        "### Parametrii"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibnL7HbE_Er3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Music samples -- has ~ 2GB\n",
        "DOWNLOAD_SAMPLE_DATASET = True  #@param {type: \"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhdeP2WuL1AE",
        "colab_type": "text"
      },
      "source": [
        "### Dependențe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl4uOyEu08xX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pandas # needed for loading the dataset\n",
        "!pip install xgboost\n",
        "\n",
        "if DOWNLOAD_SAMPLE_DATASET:\n",
        "    !pip install ffmpeg # Needed by librosa for mp3\n",
        "    !pip install librosa\n",
        "    !pip install tqdm # Progress bar for dowloading large file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOsgPbZl1_W6",
        "colab_type": "text"
      },
      "source": [
        "### Import biblioteci"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK3S5gpr2c2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if DOWNLOAD_SAMPLE_DATASET:\n",
        "    from tqdm import tqdm\n",
        "    import librosa\n",
        "\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import IPython.display as ipd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXlSfuvvzzFT",
        "colab_type": "text"
      },
      "source": [
        "### Funcții ajutătoare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWnuDNtmEyMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _reporthook(t):\n",
        "    \"\"\" ``reporthook`` to use with ``urllib.request`` that prints the process of the download.\n",
        "\n",
        "    Uses ``tqdm`` for progress bar.\n",
        "\n",
        "    **Reference:**\n",
        "    https://github.com/tqdm/tqdm\n",
        "\n",
        "    Args:\n",
        "        t (tqdm.tqdm) Progress bar.\n",
        "    \"\"\"\n",
        "    last_b = [0]\n",
        "\n",
        "    def inner(b=1, bsize=1, tsize=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            b (int, optional): Number of blocks just transferred [default: 1].\n",
        "            bsize (int, optional): Size of each block (in tqdm units) [default: 1].\n",
        "            tsize (int, optional): Total size (in tqdm units). If [default: None] remains unchanged.\n",
        "        \"\"\"\n",
        "        if tsize is not None:\n",
        "            t.total = tsize\n",
        "        t.update((b - last_b[0]) * bsize)\n",
        "        last_b[0] = b\n",
        "\n",
        "    return inner\n",
        "\n",
        "def getHomeworkArchives():\n",
        "    \"\"\" Checks if the homework dataset is present in the local directory, if not,\n",
        "    downloads it.\n",
        "    \"\"\"\n",
        "    from os import path\n",
        "\n",
        "    dataset_info = {\n",
        "        \"fma_song_info.zip\": \"http://swarm.cs.pub.ro/~gmuraru/ML/HW1/data/fma_song_info.zip\",\n",
        "        \"fma_song_samples.zip\": \"http://swarm.cs.pub.ro/~gmuraru/ML/HW1/data/fma_song_samples.zip\" # Need to upload this\n",
        "    }\n",
        "\n",
        "    for dataset_file, dataset_url in dataset_info.items():\n",
        "        if not path.isfile(dataset_file):\n",
        "            import urllib\n",
        "            with tqdm(unit='B', unit_scale=True, miniters=1, desc=dataset_file) as t:\n",
        "                urllib.request.urlretrieve(dataset_url, filename=dataset_file, reporthook=_reporthook(t))\n",
        "\n",
        "            assert(path.isfile(dataset_file))\n",
        "\n",
        "            with ZipFile(dataset_file, 'r') as zip_ref:\n",
        "                zip_ref.extractall()\n",
        "        else:\n",
        "            print(f\"{dataset_file} already in the local directory\")\n",
        "\n",
        "\n",
        "# ALL THE FUCTIONS FROM THIS POINT FORWARD ARE NEEDED ONLY IF\n",
        "# DOWNLOAD_SAMPLE_DATASET IS TRUE\n",
        "def load_tracks():\n",
        "    zipFile = ZipFile(\"fma_song_info.zip\")\n",
        "    return pd.read_csv(zipFile.open(\"song_info/tracks.csv\"), index_col=0, header=[0,1])\n",
        "\n",
        "\n",
        "def load_features():\n",
        "    zipFile = ZipFile(\"fma_song_info.zip\")\n",
        "    return pd.read_csv(zipFile.open('song_info/features.csv'), index_col=0, header=[0,1,2])\n",
        "\n",
        "\n",
        "def load_echonest():\n",
        "    zipFile = ZipFile(\"fma_song_info.zip\")\n",
        "    return pd.read_csv(zipFile.open(\"song_info/echonest.csv\"), index_col=0, header=[0,1,2])\n",
        "\n",
        "\n",
        "def get_song_path(track_id: int):\n",
        "    ''' Given a track id return the path to the sample\n",
        "\n",
        "    Args:\n",
        "        track_id (int): the id for a song found the dataset\n",
        "\n",
        "    Returns:\n",
        "        The path to the sample relative to the current directory\n",
        "    '''\n",
        "\n",
        "    return f'song_samples/{track_id:06}.mp3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxCYjmzTM82o",
        "colab_type": "text"
      },
      "source": [
        "### Descărcare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7UQywrxOaLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getHomeworkArchives()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42KuhlsjfZLR",
        "colab_type": "text"
      },
      "source": [
        "### Încărcare date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjBTENJSfbpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Echonest features for our dataset\n",
        "echonest = load_echonest()\n",
        "tracks = load_tracks()\n",
        "features = load_features()\n",
        "\n",
        "# True/False masks for selecting training/test\n",
        "train = tracks['set', 'split'] == 'training'\n",
        "test = tracks['set', 'split'].isin(['test', 'validation'])\n",
        "\n",
        "# Get X and Y\n",
        "X_train = echonest.loc[train, ('echonest', 'audio_features')]\n",
        "X_test = echonest.loc[test, ('echonest', 'audio_features')]\n",
        "\n",
        "Y_train = tracks.loc[train, ('track', 'genre_top')]\n",
        "Y_test = tracks.loc[test, ('track', 'genre_top')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiqnAbGQpEVi",
        "colab_type": "text"
      },
      "source": [
        "## 4. Problemă de rezolvat\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3X0ozpFg2Bc",
        "colab_type": "text"
      },
      "source": [
        "Impartim problema de rezolvat a acestei teme in doua subpuncte principale:\n",
        "  * Implementarea unui clasificator al genului muzical (eng. genre) pentru un anumit sample de piesă prin intermediul a patru algoritmi (KMeans, Decision Trees/Random Forest, XGBoost si SVM). Construirea unei variante de baza a clasificatorului pentru fiecare algoritm propus.\n",
        "  * Explorarea metodelor prin care pot fi imbunatatite rezultatele fiecarui algoritm in parte (e.g. varierea atributelor, prelucrarea suplimentara a atributelor, modificarea hiperparametrilor algoritmului), evaluarea comparativa intra- (i.e. fata de baseline pentru acelasi tip de algoritm) si inter-algoritm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX1b987kzGcn",
        "colab_type": "text"
      },
      "source": [
        "### 4.1. Implementare si rulare clasificatori [5pct]\n",
        "\n",
        "Pentru acest task se vor rula mai mulți algoritmi pe setul de date și vor fi notate rezultatele obținute.\n",
        "\n",
        "Veti crea cate un clasificator folosind fiecare din cei patru algoritmi din urmatoarea lista:\n",
        "  * KMeans [1 pct]\n",
        "  * Arbori de decizie, păduri aleatoare [1 pct]\n",
        "  * XGBoost [1 pct]\n",
        "  * SVM [1 pct]\n",
        "\n",
        "**Observatie 1:** Pentru KMeans, fiind **nesupervizat**, vom presupune că *nu* se știe că numărul de clustere este 4.\n",
        "\n",
        "**Observatie 2:** Algoritmii listati **nu** trebuie implementati de mana (nu obligatoriu). Este permisa utilizarea versiunilor din biblioteci cunoscute (a se vedea exemplele sugerate mai jos).\n",
        "\n",
        "\n",
        "#### **Utilizarea setului de date**\n",
        "În general, majoritatea seturilor de date sunt împărțite în:\n",
        "* setul de antrenare (eng. training dataset) - se rulează algoritmul de învățare pe acest set (eng. fit the model)\n",
        "* setul de validare (eng. validation dataset sau dev set) - se utilizează pentru modificarea hiperparametrilor algoritmului (eng. tunning the hyperparameters)\n",
        "* setul de testare (eng. testing dataset sau holdout dataset) - se rulează pentru testarea finală a algoritmului.\n",
        "\n",
        "În scheletul temei, testul de validare și de testare sunt concatenate.\n",
        "\n",
        "#### **Implementare algoritmi**\n",
        "Dezvoltati clasificatorii *baseline* pe baza fiecarui algoritm din cei listati mai sus. \n",
        "Utilizati implementarile default din bibliotecile alese pentru a obtine baseline-ul.\n",
        "Folositi drept features *audio_features* din tabela de *echonest* (sunt deja selectate în schelet).\n",
        "\n",
        "Folosiți set-ul *train* pentru antrenare și *test* pentru testare.\n",
        "\n",
        "#### **Evaluare** [1 pct]\n",
        "Gasiti [aici](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) o lista cu metrici folosite, in general, pentru  evaluarea algoritmilor de machine learning.\n",
        "\n",
        "Pentru fiecare algoritm in parte, raportati **cel putin** metricile de *accuracy*, *precision*, *recall*, *f-score* si *matricea de confuzie (eng. confusion matrix)*.\n",
        "\n",
        "\n",
        "**Observatii KMeans**\n",
        "1. Având în vedere că KMeans nu este un algoritm supervizat, putem să combinăm cele 2 seturi de date (train + testare) pentru a face clusterizarea.\n",
        "2. Aduceți valorile folosite drept *features* în intevalul [-1, 1] [standardizând datele](#scrollTo=-tkdMwB5S-as)\n",
        "3. Rulați KMeans pe setul de antrenare utilizând un număr diferit de clustere (eg. 2, 3, 4, 5, 6).\n",
        "4. Verificați utlizând metoda [silhouette](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html) care este numărul optim de clustere (puteți încerca și cu [elbow](https://www.oreilly.com/library/view/statistics-for-machine/9781788295758/c71ea970-0f3c-4973-8d3a-b09a7a6553c1.xhtml) însă va trebui să creșteți lungmea intervalului de clustere).\n",
        "5. Alegeți numărul optim de clustere și calculați **doar** *randIndex*.\n",
        "6. [Opțional] Puteți analiza coordonatele centroizilor pentru a observa cum diferă genurile muzicale în funcție de *audio_features*. \n",
        "6. [Opțional] Puteți testa să vedeți că piesele din același cluster seamănă utilizând codul de [aici](#scrollTo=fS6s1c-gPyMN).\n",
        "\n",
        "**Observatii DecisionTree/RandomForest**\n",
        "\n",
        "Implementarea sugerata este [cea](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) din biblioteca scikit-learn. \n",
        "\n",
        "**Observatii XGBoost**\n",
        "\n",
        "Implementarea sugerata este cea din biblioteca [xgboost](https://xgboost.readthedocs.io/en/latest/python/python_intro.html)\n",
        "\n",
        "**Observatii SVM**\n",
        "\n",
        "Implementarea sugerata este [cea](https://scikit-learn.org/stable/modules/svm.html) din biblioteca scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gcc_vwiS1hz",
        "colab_type": "text"
      },
      "source": [
        "#### KMeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XQh_E0xS2b0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C_Oz30Fn7L4",
        "colab_type": "text"
      },
      "source": [
        "#### Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_a_23tzpTK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GOaC0iopuAb",
        "colab_type": "text"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu5IW7s3pzB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfz0i0ggsBcQ",
        "colab_type": "text"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKdHDfursCxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwYtvPlnFBkV",
        "colab_type": "text"
      },
      "source": [
        "### 4.2. Metode de îmbunătățire și evaluare comparativă [5pct]\n",
        "\n",
        "Pentru fiecare algoritm, explorati metode prin care să îmbunătățiți performanțele de la pasul precedent (cel de realizarea a baseline-ului).\n",
        "\n",
        "**Imbunatatire algoritmi** [3 pct]\n",
        "\n",
        "Aveti in vedere urmatoarea listă de idei (și nu numai):\n",
        "* adăugarea de mai multe feature-uri (momentan la baseline s-au folosit doar *audio_features*)\n",
        "* [preprocesarea datelor](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing) (eng. data preprocessing)\n",
        "* [selectarea atributelor](https://scikit-learn.org/stable/modules/feature_selection.html) (eng. feature selection)\n",
        "* modificarea hiperparametrilor fiecarui algoritm (e.g. tipul de kernel la SVM, coeficienti de regularizare, numarul de arbori in RandomForest, adancimea arborilor in RandomForest)\n",
        "    * **Atentie!**, exemplu de **AȘA NU**:rularea cu număr maxim de 10 iterații la baseline și 100 de iterații la modelul mai bun\n",
        "\n",
        "În *fma_song_info.zip* există și un fișier *features.csv* -- detalii despre acesta se găsesc în repository-ul menționat în secțiunea [Set de date](#scrollTo=67UlrcAdqj3N).\n",
        "\n",
        "**Evaluare imbunatatiri** [2 pct]\n",
        "\n",
        "* Evaluati variantele imbunatatite ale algoritmilor, folosind 5-fold [cross-validation](https://machinelearningmastery.com/k-fold-cross-validation/). Folositi aceleasi metrici ca in cazul baseline-ului.  **Atentie!** Pentru cross-validation trebuie sa va refaceti impartirea in train/test a setului de date.\n",
        "* Realizati grafice in care sa aratati analiza intra-algoritm a performantei imbunatatirii (e.g. folositi un bar chart pentru a compara accuracy-ul variantei baseline a RandomForest cu cea a variantei imbunatatite)\n",
        "* Realizati grafice in care sa aratati analiza inter-algoritm a performantelor. Faceti cate un grafic per metrica (e.g. accuracy, precision, recall) in care sa includeti valorile obtinute de fiecare algoritm imbunatatit in parte. \n",
        "* Redactati, pe seama graficelor, o analiza a acestora, evidentiind avantajele si dezavantajele fiecarui algoritm implementat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7t02xIht9rK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0gPDAkaF5Fy",
        "colab_type": "text"
      },
      "source": [
        "### 5. Mențiuni\n",
        "\n",
        "**Pentru rezolvarea task-urilor puteți folosi orice bibliotecă doriți.**\n",
        "\n",
        "În scheletul temei, datele sunt încărcate folosind biblioteca [pandas](https://pandas.pydata.org/), însă puteți utiliza orice bibliotecă doriți.\n",
        "\n",
        "**Algoritmii nu trebuie implementați de mână.**\n",
        "\n",
        "\"Rezolvarea\" unei probleme de învățare automată se reduce la îmbunătățirea unei metrici.\n",
        "\n",
        "Un prim pas important este reprezentat de crearea unui *baseline* sau a unei soluții banale, de start (eng. *vanilla solution*) și măsurarea acesteia.\n",
        "\n",
        "Următorul pas îl reprezintă o serie de modificări aduse feature setului sau algoritmului de învățăre. Aceast pas reprezintă o iterație peste soluția inițială.\n",
        "\n",
        "Tot procesul constă în aplicarea mai multor *iterații* până se ajunge la o valoare a metricii suficient de bună pentru problema de rezolvat. În cazul nostru, această valoare este reprezentată de ambiția fiecăruia dintre voi :)\n",
        "\n",
        "**Recomandări**:\n",
        "* biblioteca [sklearn](https://scikit-learn.org/) - oferă o colecție algoritmi de învățare automată, metrici, metode de selectare de caractaristici, etc.\n",
        "* pentru XGBoost puteți folosit biblioteca [xgboost](https://xgboost.readthedocs.io/en/latest/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS6s1c-gPyMN",
        "colab_type": "text"
      },
      "source": [
        "### 6. Sample test\n",
        "Biblioteca [librosa](https://librosa.github.io/librosa/) permite analizarea și redarea sunetelor.\n",
        "\n",
        "Se poate folosi pentru a observa dacă anumite melodii găsite într-un anumit gen muzical sunt asemănătoare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izobnGMbQqIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "track_test = tracks[test].sample(1)\n",
        "title = track_test[('track', 'title')].values[0]\n",
        "genre = track_test[('track', 'genre_top')].values[0]\n",
        "print(f\"Song\\n\\ttitle: {title}\\n\\tgenre {genre}\")\n",
        "\n",
        "song_path = get_song_path(track_test.index.values[0])\n",
        "song, rate = librosa.load(song_path)\n",
        "ipd.Audio(song, rate=rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tkdMwB5S-as",
        "colab_type": "text"
      },
      "source": [
        "### 7. Link-uri utile\n",
        "* [Evaluarea algoritmilor de clusterizare](https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html)\n",
        "* [Standardizare vs Normalizare](https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHfxzF2Omi_G",
        "colab_type": "text"
      },
      "source": [
        "## Bibliografie\n",
        "<a name=\"fma\">[1] *Michaël Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson, FMA: A Dataset For Music Analysis, 18th International Society for Music Information Retrieval Conference, 2017*</a>\n",
        "\n"
      ]
    }
  ]
}